---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>


My name is Jingyan Shen. I am a first-year CS Ph.D. student at New York University, advised by Prof. [Matus Telgarsky](https://cims.nyu.edu/~matus/) and Prof. [Pavel Izmailov](https://izmailovpavel.github.io/). Previously, I earned my dual master degree from Tsinghua University and Columbia University. Prior to this, I completed my Bachelor's degree at Wuhan University, majoring in Statistics. 

My current research focuses on **advancing the reasoning capabilities of large language models through reinforcement learning**, integrating theoretical insights with the development of practical algorithms. 

<!-- <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->

# üî• News
- *2025.09*: &nbsp;üöÄüöÄ One paper accepted by NeurIPS 2025. See you in San Diego!
- *2025.08*: &nbsp;üöÄüöÄ [MiCRo](https://arxiv.org/pdf/2505.24846) has been accepted by EMNLP 2025 Main Conference (with award nomination)! 
- *2025.05*: &nbsp;üéâüéâ One paper accepted by ICML 2025. 
- *2025.01*: &nbsp;üéâüéâ [TimeInf](https://arxiv.org/pdf/2407.15247) has been accepted by ICLR 2025. 

# üìù Preprints and Publications 
(<sup>‚Ä†</sup>: equal contribution)

Publications:  

- **MiCRo: Mixture Modeling and Context-aware Routing for Personalized Preference Learning**
  
  **Jingyan Shen**<sup>‚Ä†</sup>, Jiarui Yao<sup>‚Ä†</sup>, Rui Yang<sup>‚Ä†</sup>, Yifan Sun, Feng Luo, Rui Pan, Tong Zhang, Han Zhao  
  <span style="color:blue;">EMNLP</span> 2025 (Main) <span style="color:red;">Outstanding Paper Award</span> \[[Paper](https://arxiv.org/pdf/2505.24846)\]
  
- **Improving Data Efficiency for LLM Reinforcement Fine-tuning Through Difficulty-targeted Online Data Selection and Rollout Replay**

  Yifan Sun<sup>‚Ä†</sup>, **Jingyan Shen**<sup>‚Ä†</sup>, Yibin Wang<sup>‚Ä†</sup>, Tianyu Chen, Zhendong Wang, Mingyuan Zhou, Huan Zhang
  <span style="color:blue;">NeurIPS</span> 2025 \[[Paper](https://arxiv.org/pdf/2506.05316)\]

- **Conformal Tail Risk Control for Large Language Model Alignment**

  Catherine Chen,  **Jingyan Shen**, Zhun Deng, Lihua Lei  
  <span style="color:blue;">ICML</span> 2025 \[[Paper](https://arxiv.org/abs/2502.20285)\]

- **Rethinking Diverse Human Preference Learning through Principal Component Analysis**

  Feng Luo, Rui Yang, Hao Sun, Chunyuan Deng, Jiarui Yao, **Jingyan Shen**, Huan Zhang, Hanjie Chen  
  <span style="color:blue;">ACL</span> 2025 (Findings) \[[Paper](https://arxiv.org/pdf/2502.13131)\]

- **TimeInf: Time Series Data Contribution via Influence Functions**

  Yizi Zhang<sup>‚Ä†</sup>,  **Jingyan Shen**<sup>‚Ä†</sup>, Xiaoxue Xiong<sup>‚Ä†</sup>, Yongchan Kwon  
  <span style="color:blue;">ICLR</span> 2025 \[[Paper](https://arxiv.org/pdf/2407.15247)\] \[[Code](https://github.com/yzhang511/TimeInf)\] 


- **2D-OOB: Attributing Data Contribution through Joint Valuation Framework**

  Yifan Sun<sup>‚Ä†</sup>,  **Jingyan Shen**<sup>‚Ä†</sup>, Yongchan Kwon  
  <span style="color:blue;">NeurIPS</span> 2024 \[[Paper](https://arxiv.org/abs/2408.03572)\] \[[Code](https://github.com/yifansun99/2D-OOB-Joint-Valuation)\] 


<!-- 
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

Yizi Zhang$^\dag$,  **Jingyan Shen**$^\dag$, Xiaoxue Xiong$^\dag$, and Yongchan Kwon

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

# üéñ Honors and Awards
- Outstanding Graduate Student (Top 1%), Tsinghua University, 2024
- Excellent Graduate Thesis Award, Tsinghua University, 2024
- Graduate Fellowship, Columbia University, 2023
- Outstanding Undergraduate Student, Wuhan University, 2021
- National Scholarship for Undergraduates, Ministry of Education of China, 2018

<!-- # üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)-->

# üíª Industry Experience
- *2024.02 - 2025.06*, Full-time machine learning engineer at Pinterest

# üåü Hobbies
Outside of research, I enjoy playing table tennis and tennis. I‚Äôm always excited to dive into a good book or explore new places when I travel.